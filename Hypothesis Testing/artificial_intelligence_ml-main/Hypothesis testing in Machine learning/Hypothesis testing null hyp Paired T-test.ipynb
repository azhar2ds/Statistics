{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis testing in Machine learning using Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is hypothesis testing ?\n",
    "Hypothesis testing is a statistical method that is used in making statistical decisions using experimental data. Hypothesis Testing is basically an assumption that we make about the population parameter.\n",
    "\n",
    "* Ex : you say avg student in class is 40 or a boy is taller than girls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. why do we use it ?\n",
    "\n",
    "**Hypothesis testing** is an essential procedure in statistics. A **hypothesis test** evaluates two mutually exclusive statements about a population to determine which statement is best supported by the sample data. When we say that a finding is statistically significant, it’s thanks to a **hypothesis test**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. what are basic of hypothesis ?\n",
    "![](./image/1_U-cR-vP8pYUmLUDwCPv23A.png)\n",
    "\n",
    "The basic of hypothesis is normalisation and standard normalisation. all our hypothesis is revolve around basic of these 2 terms. let’s see these.\n",
    "\n",
    "![](./image/1_2vTwIrqdELKJY-tpheO7GA.jpeg)\n",
    "\n",
    "\n",
    "You must be wondering what’s difference between these two image, one might say i don’t find, while other will see some flatter graph compare to steep. \n",
    "\n",
    "well buddy this is not what i want to represent , in 1st first you can see there are different normal curve all those normal curve can have different mean’s and variances where as in 2nd image if you notice the graph is properly distributed and mean =0 and variance =1 always. \n",
    "\n",
    "concept of z-score comes in picture when we use standardised normal data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution -\n",
    "\n",
    "A variable is said to be normally distributed or have a normal distribution if its distribution has the shape of a normal curve — a special bell-shaped curve. … The graph of a normal distribution is called the normal curve, which has all of the following properties: 1. The mean, median, and mode are equal.\n",
    "\n",
    "![](./image/1_gBnxoTRwo9sDovvegHfm6g.png)\n",
    "\n",
    "## Standardised Normal Distribution —\n",
    "\n",
    "A standard normal distribution is a normal distribution with mean 0 and standard deviation 1.\n",
    "\n",
    "![](./image/1_UY43iz5Uesa1m9ItIrxYCg.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which are important parameter of hypothesis testing ?\n",
    "Null hypothesis :- In inferential statistics, the null hypothesis is a general statement or default position that there is no relationship between two measured phenomena, or no association among groups\n",
    "In other words it is a basic assumption or made based on domain or problem knowledge.\n",
    "* Example : a company production is = 50 unit/per day etc.\n",
    "\n",
    "## Alternative hypothesis :-\n",
    "The alternative hypothesis is the hypothesis used in hypothesis testing that is contrary to the null hypothesis. It is usually taken to be that the observations are the result of a real effect (with some amount of chance variation superposed)\n",
    "* Example : a company production is !=50 unit/per day etc.\n",
    "\n",
    "![](./image/1_fEPOHXPQO_ZNJC4UQDXmqw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level of significance: \n",
    "\n",
    "Refers to the degree of significance in which we accept or reject the null-hypothesis. 100% accuracy is not possible for accepting or rejecting a hypothesis, so we therefore select a level of significance that is usually 5%.\n",
    "\n",
    "This is normally denoted with alpha(maths symbol ) and generally it is 0.05 or 5% , which means your output should be 95% confident to give similar kind of result in each sample.\n",
    "\n",
    "\n",
    "## Type I error: \n",
    "When we reject the null hypothesis, although that hypothesis was true. Type I error is denoted by alpha. In hypothesis testing, the normal curve that shows the critical region is called the alpha region\n",
    "\n",
    "## Type II errors: \n",
    "When we accept the null hypothesis but it is false. Type II errors are denoted by beta. In Hypothesis testing, the normal curve that shows the acceptance region is called the beta region.\n",
    "\n",
    "## One tailed test :\n",
    "\n",
    "- A test of a statistical hypothesis , where the region of rejection is on only one side of the sampling distribution , is called a one-tailed test.\n",
    "\n",
    "Example :- a college has ≥ 4000 student or data science ≤ 80% org adopted.\n",
    "## Two-tailed test :\n",
    "- A two-tailed test is a statistical test in which the critical area of a distribution is two-sided and tests whether a sample is greater than or less than a certain range of values. If the sample being tested falls into either of the critical areas, the alternative hypothesis is accepted instead of the null hypothesis.\n",
    "\n",
    "Example : a college != 4000 student or data science != 80% org adopted\n",
    "\n",
    "![](./image/1_Fwmazvo993cH6q79bpfeIw.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-value :\n",
    "- The P value, or calculated probability, is the probability of finding the observed, or more extreme, results when the null hypothesis (H 0) of a study question is true — the definition of ‘extreme’ depends on how the hypothesis is being tested.\n",
    "\n",
    "If your P value is less than the chosen significance level then you reject the null hypothesis i.e. accept that your sample gives reasonable evidence to support the alternative hypothesis. It does NOT imply a “meaningful” or “important” difference; that is for you to decide when considering the real-world relevance of your result.\n",
    "Example : you have a coin and you don’t know whether that is fair or tricky so let’s decide null and alternate hypothesis\n",
    "\n",
    "    - H0 : a coin is a fair coin.\n",
    "    - H1 : a coin is a tricky coin. and alpha = 5% or 0.05\n",
    "\n",
    "Now let’s toss the coin and calculate p- value ( probability value).\n",
    "\n",
    "- Toss a coin 1st time and result is tail- P-value = 50% (as head and tail have equal probability)\n",
    "\n",
    "- Toss a coin 2nd time and result is tail, now p-value = 50/2 = 25%\n",
    "\n",
    "and similarly we Toss 6 consecutive time and got result as P-value = 1.5% but we set our significance level as 95% means 5% error rate we allow and here we see we are beyond that level i.e. our null- hypothesis does not hold good so we need to reject and propose that this coin is a tricky coin which is actually.\n",
    "\n",
    "## Degree of freedom :\n",
    "- Now imagine you’re not into hats. You’re into data analysis.You have a data set with 10 values. If you’re not estimating anything, each value can take on any number, right? Each value is completely free to vary.But suppose you want to test the population mean with a sample of 10 values, using a 1-sample t test. You now have a constraint — the estimation of the mean. What is that constraint, exactly? By definition of the mean, the following relationship must hold: The sum of all values in the data must equal n x mean, where n is the number of values in the data set.\n",
    "\n",
    "So if a data set has 10 values, the sum of the 10 values must equal the mean x 10. If the mean of the 10 values is 3.5 (you could pick any number), this constraint requires that the sum of the 10 values must equal 10 x 3.5 = 35.\n",
    "\n",
    "With that constraint, the first value in the data set is free to vary. Whatever value it is, it’s still possible for the sum of all 10 numbers to have a value of 35. The second value is also free to vary, because whatever value you choose, it still allows for the possibility that the sum of all the values is 35.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Let’s see some of widely used hypothesis testing type :-\n",
    "1- T Test ( Student T test)\n",
    "\n",
    "2- Z Test\n",
    "\n",
    "3- ANOVA Test\n",
    "\n",
    "4- Chi-Square Test\n",
    "\n",
    "\n",
    "\n",
    "### T- Test :\n",
    "\n",
    "- A t-test is a type of inferential statistic which is used to determine if there is a significant difference between the means of two groups which may be related in certain features. It is mostly used when the data sets, like the set of data recorded as outcome from flipping a coin a 100 times, would follow a normal distribution and may have unknown variances. T test is used as a hypothesis testing tool, which allows testing of an assumption applicable to a population.\n",
    "\n",
    "-> T-test has 2 types : 1. one sampled t-test 2. two-sampled t-test.\n",
    "\n",
    "One sample t-test : The One Sample t Test determines whether the sample mean is statistically different from a known or hypothesised population mean. The One Sample t Test is a parametric test.\n",
    "Example :- you have 10 ages and you are checking whether avg age is 30 or not. (check code below for that using python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats import weightstats as stests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>sex</th>\n",
       "      <th>agegrp</th>\n",
       "      <th>bp_before</th>\n",
       "      <th>bp_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>30-45</td>\n",
       "      <td>143</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>30-45</td>\n",
       "      <td>163</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>30-45</td>\n",
       "      <td>153</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>30-45</td>\n",
       "      <td>153</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>30-45</td>\n",
       "      <td>146</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient   sex agegrp  bp_before  bp_after\n",
       "0        1  Male  30-45        143       153\n",
       "1        2  Male  30-45        163       170\n",
       "2        3  Male  30-45        153       168\n",
       "3        4  Male  30-45        153       142\n",
       "4        5  Male  30-45        146       141"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"blood_pressure.csv\")\n",
    "df[['bp_before','bp_after']].describe()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011297914644840823\n"
     ]
    }
   ],
   "source": [
    "ttest,pval = stats.ttest_rel(df['bp_before'], df['bp_after'])\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paired sampled t-test :- The paired sample t-test is also called dependent sample t-test. It’s an uni variate test that tests for a significant difference between 2 related variables. An example of this is if you where to collect the blood pressure for an individual before and after some treatment, condition, or time point.\n",
    "- H0 :- means difference between two sample is 0\n",
    "- H1:- mean difference between two sample is not 0\n",
    "check the code below for same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "if pval<0.05:\n",
    "    print(\"reject null hypothesis\")\n",
    "else:\n",
    "    print(\"accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When you can run a Z Test.\n",
    "Several different types of tests are used in statistics (i.e. f test, chi square test, t test). You would use a Z test if:\n",
    "* Your sample size is greater than 30. Otherwise, use a t test.\n",
    "* Data points should be independent from each other. In other words, one data point isn’t related or doesn’t affect another data point.\n",
    "* Your data should be normally distributed. However, for large sample sizes (over 30) this doesn’t always matter.\n",
    "* Your data should be randomly selected from a population, where each item has an equal chance of being selected.\n",
    "* Sample sizes should be equal if at all possible.\n",
    "\n",
    "Example again we are using z-test for blood pressure with some mean like 156 (python code is below for same) one-sample Z test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6651614730255063\n",
      "accept null hypothesis\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats import weightstats as stests\n",
    "ztest ,pval = stests.ztest(df['bp_before'], x2=None, value=156)\n",
    "print(float(pval))\n",
    "if pval<0.05:\n",
    "    print(\"reject null hypothesis\")\n",
    "else:\n",
    "    print(\"accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-sample Z test- In two sample z-test , similar to t-test here we are checking two independent data groups and deciding whether sample mean of two group is equal or not.\n",
    "- H0 : mean of two group is 0\n",
    "- H1 : mean of two group is not 0\n",
    "Example : we are checking in blood data after blood and before blood data.(code in python below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002162306611369422\n",
      "accept null hypothesis\n"
     ]
    }
   ],
   "source": [
    "ztest ,pval1 = stests.ztest(df['bp_before'], x2=df['bp_after'], value=0,alternative='two-sided')\n",
    "print(float(pval1))\n",
    "if pval<0.05:\n",
    "    print(\"reject null hypothesis\")\n",
    "else:\n",
    "    print(\"accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for significance is:  0.0159099583256229\n",
      "reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "df_anova = pd.read_csv('PlantGrowth.csv')\n",
    "df_anova = df_anova[['weight','group']]\n",
    "\n",
    "grps = pd.unique(df_anova.group.values)\n",
    "d_data = {grp:df_anova['weight'][df_anova.group == grp] for grp in grps}\n",
    " \n",
    "F, p = stats.f_oneway(d_data['ctrl'], d_data['trt1'], d_data['trt2'])\n",
    "\n",
    "print(\"p-value for significance is: \", p)\n",
    "\n",
    "if p<0.05:\n",
    "    print(\"reject null hypothesis\")\n",
    "else:\n",
    "    print(\"accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA (F-TEST) :\n",
    "- The t-test works well when dealing with two groups, but sometimes we want to compare more than two groups at the same time. For example, if we wanted to test whether voter age differs based on some categorical variable like race, we have to compare the means of each level or group the variable. We could carry out a separate t-test for each pair of groups, but when you conduct many tests you increase the chances of false positives. The analysis of variance or ANOVA is a statistical inference test that lets you compare multiple groups at the same time.\n",
    "\n",
    "**F = Between group variability / Within group variability**\n",
    "\n",
    "![](./image/1_SV4xlXEFCKzgT4PbB6nlgA.png)\n",
    "\n",
    "\n",
    "Unlike the z and t-distributions, the F-distribution does not have any negative values because between and within-group variability are always positive due to squaring each deviation.\n",
    "One Way F-test(Anova) :- It tell whether two or more groups are similar or not based on their mean similarity and f-score.\n",
    "Example : there are 3 different category of plant and their weight and need to check whether all 3 group are similar or not (code in python below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for significance is:  0.0159099583256229\n",
      "reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "df_anova = pd.read_csv('PlantGrowth.csv')\n",
    "df_anova = df_anova[['weight','group']]\n",
    "grps = pd.unique(df_anova.group.values)\n",
    "d_data = {grp:df_anova['weight'][df_anova.group == grp] for grp in grps}\n",
    " \n",
    "F, p = stats.f_oneway(d_data['ctrl'], d_data['trt1'], d_data['trt2'])\n",
    "print(\"p-value for significance is: \", p)\n",
    "if p<0.05:\n",
    "    print(\"reject null hypothesis\")\n",
    "else:\n",
    "    print(\"accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Way F-test :\n",
    "- Two way F-test is extension of 1-way f-test, it is used when we have 2 independent variable and 2+ groups. 2-way F-test does not tell which variable is dominant. if we need to check individual significance then Post-hoc testing need to be performed.\n",
    "Now let’s take a look at the Grand mean crop yield (the mean crop yield not by any sub-group), as well the mean crop yield by each factor, as well as by the factors grouped together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "df_anova2 = pd.read_csv(\"https://raw.githubusercontent.com/Opensourcefordatascience/Data-sets/master/crop_yield.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall model F( 3, 16) =  4.112, p =  0.0243\n"
     ]
    }
   ],
   "source": [
    "model = ols('Yield ~ C(Fert)*C(Water)', df_anova2).fit()\n",
    "\n",
    "# Seeing if the overall model is significant\n",
    "print(f\"Overall model F({model.df_model: .0f},{model.df_resid: .0f}) = {model.fvalue: .3f}, p = {model.f_pvalue: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Yield</td>      <th>  R-squared:         </th> <td>   0.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 11 Jul 2021</td> <th>  Prob (F-statistic):</th>  <td>0.0243</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:52:27</td>     <th>  Log-Likelihood:    </th> <td> -50.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    20</td>      <th>  AIC:               </th> <td>   110.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    16</td>      <th>  BIC:               </th> <td>   114.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                    <td>   31.8000</td> <td>    1.549</td> <td>   20.527</td> <td> 0.000</td> <td>   28.516</td> <td>   35.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Fert)[T.B]</th>                 <td>   -1.9600</td> <td>    2.191</td> <td>   -0.895</td> <td> 0.384</td> <td>   -6.604</td> <td>    2.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Water)[T.Low]</th>              <td>   -1.8000</td> <td>    2.191</td> <td>   -0.822</td> <td> 0.423</td> <td>   -6.444</td> <td>    2.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Fert)[T.B]:C(Water)[T.Low]</th> <td>   -3.5200</td> <td>    3.098</td> <td>   -1.136</td> <td> 0.273</td> <td>  -10.088</td> <td>    3.048</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.427</td> <th>  Durbin-Watson:     </th> <td>   2.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.180</td> <th>  Jarque-Bera (JB):  </th> <td>   1.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.082</td> <th>  Prob(JB):          </th> <td>   0.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.752</td> <th>  Cond. No.          </th> <td>    6.85</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Yield   R-squared:                       0.435\n",
       "Model:                            OLS   Adj. R-squared:                  0.330\n",
       "Method:                 Least Squares   F-statistic:                     4.112\n",
       "Date:                Sun, 11 Jul 2021   Prob (F-statistic):             0.0243\n",
       "Time:                        10:52:27   Log-Likelihood:                -50.996\n",
       "No. Observations:                  20   AIC:                             110.0\n",
       "Df Residuals:                      16   BIC:                             114.0\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================================\n",
       "                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------\n",
       "Intercept                       31.8000      1.549     20.527      0.000      28.516      35.084\n",
       "C(Fert)[T.B]                    -1.9600      2.191     -0.895      0.384      -6.604       2.684\n",
       "C(Water)[T.Low]                 -1.8000      2.191     -0.822      0.423      -6.444       2.844\n",
       "C(Fert)[T.B]:C(Water)[T.Low]    -3.5200      3.098     -1.136      0.273     -10.088       3.048\n",
       "==============================================================================\n",
       "Omnibus:                        3.427   Durbin-Watson:                   2.963\n",
       "Prob(Omnibus):                  0.180   Jarque-Bera (JB):                1.319\n",
       "Skew:                          -0.082   Prob(JB):                        0.517\n",
       "Kurtosis:                       1.752   Cond. No.                         6.85\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(Fert)</th>\n",
       "      <td>69.192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.766000</td>\n",
       "      <td>0.028847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(Water)</th>\n",
       "      <td>63.368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.280667</td>\n",
       "      <td>0.035386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(Fert):C(Water)</th>\n",
       "      <td>15.488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.290667</td>\n",
       "      <td>0.272656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>192.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sum_sq    df         F    PR(>F)\n",
       "C(Fert)            69.192   1.0  5.766000  0.028847\n",
       "C(Water)           63.368   1.0  5.280667  0.035386\n",
       "C(Fert):C(Water)   15.488   1.0  1.290667  0.272656\n",
       "Residual          192.000  16.0       NaN       NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = sm.stats.anova_lm(model, typ= 2)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Square Test:\n",
    "\n",
    "- The test is applied when you have two categorical variables from a single population. It is used to determine whether there is a significant association between the two variables.\n",
    "\n",
    "For example, in an election survey, voters might be classified by gender (male or female) and voting preference (Democrat, Republican, or Independent). We could use a chi-square test for independence to determine whether gender is related to voting preference\n",
    "check example in python below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chi = pd.read_csv('chi-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contingency_table :-\n",
      " Like Shopping?  No  Yes\n",
      "Gender                 \n",
      "Female           2    3\n",
      "Male             2    2\n"
     ]
    }
   ],
   "source": [
    "contingency_table=pd.crosstab(df_chi[\"Gender\"],df_chi[\"Like Shopping?\"])\n",
    "print('contingency_table :-\\n',contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Values :-\n",
      " [[2 3]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "#Observed Values\n",
    "Observed_Values = contingency_table.values \n",
    "print(\"Observed Values :-\\n\",Observed_Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Values :-\n",
      " [[2.22222222 2.77777778]\n",
      " [1.77777778 2.22222222]]\n"
     ]
    }
   ],
   "source": [
    "b=stats.chi2_contingency(contingency_table)\n",
    "Expected_Values = b[3]\n",
    "print(\"Expected Values :-\\n\",Expected_Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree of Freedom:-      patient     sex agegrp  bp_before  bp_after\n",
      "0          1    Male  30-45        143       153\n",
      "1          2    Male  30-45        163       170\n",
      "2          3    Male  30-45        153       168\n",
      "3          4    Male  30-45        153       142\n",
      "4          5    Male  30-45        146       141\n",
      "..       ...     ...    ...        ...       ...\n",
      "115      116  Female    60+        152       152\n",
      "116      117  Female    60+        161       152\n",
      "117      118  Female    60+        165       174\n",
      "118      119  Female    60+        149       151\n",
      "119      120  Female    60+        185       163\n",
      "\n",
      "[120 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "no_of_rows=len(contingency_table.iloc[0:2,0])\n",
    "no_of_columns=len(contingency_table.iloc[0,0:2])\n",
    "df11=(no_of_rows-1)*(no_of_columns-1)\n",
    "print(\"Degree of Freedom:-\",df)\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi-square statistic:- 0.09000000000000008\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import chi2\n",
    "chi_square=sum([(o-e)**2./e for o,e in zip(Observed_Values,Expected_Values)])\n",
    "chi_square_statistic=chi_square[0]+chi_square[1]\n",
    "print(\"chi-square statistic:-\",chi_square_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critical_value: 3.841458820694124\n"
     ]
    }
   ],
   "source": [
    "critical_value=chi2.ppf(q=1-alpha,df=df11)\n",
    "print('critical_value:',critical_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.7641771556220945\n"
     ]
    }
   ],
   "source": [
    "#p-value\n",
    "p_value=1-chi2.cdf(x=chi_square_statistic,df=df11)\n",
    "print('p-value:',p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significance level:  0.05\n",
      "Degree of Freedom:  1\n",
      "chi-square statistic: 0.09000000000000008\n",
      "critical_value: 3.841458820694124\n",
      "p-value: 0.7641771556220945\n"
     ]
    }
   ],
   "source": [
    "print('Significance level: ',alpha)\n",
    "print('Degree of Freedom: ',df11)\n",
    "print('chi-square statistic:',chi_square_statistic)\n",
    "print('critical_value:',critical_value)\n",
    "print('p-value:',p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retain H0,There is no relationship between 2 categorical variables\n",
      "Retain H0,There is no relationship between 2 categorical variables\n"
     ]
    }
   ],
   "source": [
    "if chi_square_statistic>=critical_value:\n",
    "    print(\"Reject H0,There is a relationship between 2 categorical variables\")\n",
    "else:\n",
    "    print(\"Retain H0,There is no relationship between 2 categorical variables\")\n",
    "    \n",
    "if p_value<=alpha:\n",
    "    print(\"Reject H0,There is a relationship between 2 categorical variables\")\n",
    "else:\n",
    "    print(\"Retain H0,There is no relationship between 2 categorical variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
